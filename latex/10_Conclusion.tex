\chapter{Conclusions and Future Work}
\label{chap:conclusion}
\section{Summary}
In this thesis, a preliminary look at the robustness of offline data-driven LMIs was presented as a surrogate for machine learning problems whose solutions can be found via convex optimization.  These methods consisted of searches with various constraints (Lyapunov stability, $\mathcal{H}_{2}$ optimality, $\mathcal{H}_{\infty}$ optimality) which calculate static state feedback control parameters, with or without intermediate system identification.

When subjected to scaled single-parameter uncertainty, the data-driven approaches could synthesize a stable, robust controller which performed adequately on the full system.  However, this ability deteriorated as the scale factor increased.  Specific cut-off values varied across the case studies - approximately 30\% for the double integrator, 10\% for the cart pole, and 30\% for the robot arm.  For the fraction of stable controllers, robustness metrics were relatively constant as a function of scale factor.

When subjected to scaled measurement noise, the the direct LMI-based approach worked poorly, and did not work at all when the scale factor was above 10\%.  The indirect SVD-based approaches performed marginally better for double integrator and robot arm but still did not work 100\% of the time.  There is no precise cut-off, but the fraction of stable controllers trends downward as scale factor increases.  For the cart pole however, the indirect SVD-based approach did well to suppress noise and extract a linear plant model from its dynamic modes.

When adjusting the performance objective used for direct LMI-based approaches, there was a slight increase in the percentage of stabilizing controllers, although their performance varies from the LQ baseline as expected.  This had little effect on the ability to synthesize controllers from noisy training data, however.

\section{Tentative Conclusions}
While many factors are held constant (e.g. the training policy, the amount of data used for learning, the performance cost parameters) and simplifying assumptions were made (e.g., no rate limits or saturation, simplified inertial properties), it was demonstrated that the model-free data-driven approaches can tolerate low to moderate amounts of single parameter uncertainty.  Also, additive measurement noise can be handled to a certain degree only by using the indirect SVD-based approach, which inherently suppresses uncorrelated noise (data not attributable to the transient of a dynamic mode).  Thus, even when no exact solution exists to the optimization problem, the SVD-based least squares solution effectively produces a practically usable suboptimal solution.

The poor performance of data-driven LMIs with noisy data is expected based on the assumption of having perfect state feedback.  When this is not the case, the resulting problem can become non-convex to the point of infeasibility, resulting in the LMI solver returning a ``no solution'' condition, when in reality, there is likely a nearby suboptimal solution which stabilizes the system.  It seems necessary to encode some expected performance loss or expected uncertainty into the LMI, or more generally, seek to understand the optimization landscape of the control problem with respect to both stability \underline{and} various metrics of robustness.  Whether this combined search problem is computationally feasible in a data-driven/reinforcement learning paradigm is left for future work.

It was also demonstrated that, when solving for baseline $\mathcal{H}_{\infty}$-optimal control using the DGARE and bisection, the minimax/optimal value of disturbance attenuation constant $\gamma^{*}$ produced fragile feedback systems whose responses to the modeled disturbances are evenly ``spread'' throughout all frequencies.  However, by relaxing the optimality of the synthesis procedure with respect to the desired $\gamma \geq \gamma^{*}$, this effect becomes less prominent.  For all three case studies, this ``waterbed effect'' was clear when examining the frequency-dependent ``loop shape'' of the generalized plant's singular values.

\section{Additional Remarks}
Apart from the specific numerical results, several additional lessons were learned while developing this thesis.

The field of robust control, with its associated tools and techniques, is both very powerful and very mathematically involved.  However, it is heavily dependent on dynamic modeling of the uncertain system to be controlled.  Fortunately, modern software toolboxes/libraries can automate the solution to control design when transcribed as a mathematical optimization, but only when provided an accurate model of the disturbances and/or uncertainty faced by the real system.  Indeed, much of the practical work involved with robust control involves derivation of disturbance models and heuristic tuning of either control gains or cost weights used to compute control gains; in both cases, one leans heavily on domain-specific insight into the system being controlled.

By contrast, literature in some more computationally-focused aspects of control theory, including data-driven control and learning/optimization, often focuses more on theoretical aspects of algorithms (e.g. convergence properties, convexity, sample efficiency).  To this end, the case study dynamical systems used to test and verify numerical techniques are purposely simplified or generalized to omit the practical aspects of incorporating real-world effects into the system being learned/optimized.  Incorporating, for example, low-frequency parameter uncertainty or measurement noise (or uncertainty induced by state estimation) is not immediately obvious, or possibly feasible, using standard convex optimization paradigms.  Many similar problems are the subject of current research in robust learning.

When exploring the intersection between these two fields, as was initially the goal of this thesis, it is important to pick and focus on a somewhat smaller problem to benchmark.  Maintaining and tuning multiple simulators with a large number of parameters (e.g., cost weights, training policies and durations, plant inertial parameters, measurement noise models, initial conditions for simulation, disturbance models) and attempting to analyze properties empirically (e.g. using repeated-trial or Monte-Carlo type tests) can quickly overshadow the exploration of important theoretical properties.  Put another way, the efficacy and robustness of data-driven control depends on a wide range of factors, and evaluating different aspects is best done incrementally using smaller, more targeted analyses on a particular system.  For example, focusing on the cart pole for future analysis may allow comparison to known results in robustness/sensitivity \cite{leong2016understanding,bernat2020driver}.

\section{Future Work}
Several areas of this work were purposely oversimplified in the interest of time, and would be interesting to explore further.
\begin{itemize}
\item{\textbf{Loop Shaping:} The time-domain, game-theoretic solution to $\mathcal{H}_{\infty}$ control used in this work operates on a general state-space representation of the plant.  Cost and disturbance weights are constant matrices which are independent of frequency.  In order to utilize loop-shaping techniques, the plant's state-space model would need to be augmented with loop-shaping filters.  Interestingly, the data-driven equivalent of this problem was considered in \cite{berberich2022combining}, treating this augmented plant as partially known; filter dynamics are known, but the system dynamics are learned from data.  This seems like the right approach for further investigation of data-driven $\mathcal{H}_{\infty}$ and possibly the effect of state estimation on loop shape.  For example, robotic control involving frequency-dependent actuator dynamics may benefit from loop-shaping designs.
}
%
\item{\textbf{Disturbance Modeling:}
Disturbance modeling is an important aspect of robust control.  In order to leverage tools from robust control into model-free learning however, more difficult questions arise.  How much of the system is understood and/or modeled?  Can disturbances be modeled in a way which is flexible enough to incorporate new data that contradicts the \emph{a priori} model?  In the specific context of this work, one direction which should be expanded on is the effect of cost weighting matrices other than those associated with LQ performance.  It would be interesting to study how different performance and disturbance weights perform in model-based contexts vs. model-free contexts.  Perhaps higher-dimensional statistical techniques could be used to estimate disturbance bounds from gathered data.
}
%
\item{\textbf{Optimization Algorithms:}
This thesis aimed to evaluate specific offline techniques from \cite{de2019formulas} in the presence of uncertainty and noise.  But, many applications of reinforcement learning are based on the assumption of online adaptation of the objective function.  In particular, RL often involves some form of policy optimization, which can include, e.g., policy gradient methods, actor-critic methods, trust-region methods, etc.  For the LQR problem, these approaches are well-understood \cite{malik2019derivative}.  Extensions to LQG control \cite{zheng2022escaping, umenberger2022globally} and mixed $\mathcal{H}_{2}$/$\mathcal{H}_{\infty}$ control \cite{zhang2021derivative, zhang2020policy} have been investigated, but are noted as being non-convex.  Thus, future work in data-driven optimization should investigate algorithms for non-convex problems.  Similarly, optimization approaches which explicitly consider uncertainty in the problem data seem particularly relevant.  Indeed, the results of this thesis illustrate clearly that optimizing under the assumption of perfect state feedback is likely to be insufficient in scenarios with high uncertainty/noise.  Optimization algorithms which deal with uncertainty have been developed using the theoretical framework known as ``robust optimization'' \cite{soyster1973convex, ei1997robust, el1998robust, ben1999robust, ben2001lectures, ben2002robust, bertsimas2003robust, bertsimas2004price, chaerani2006modeling, joelianto5417249}.
}
%
\item{\textbf{Non-Robotic Systems:}
For the purposes of this work, robotic systems were selected for theoretical simplicity.  The practical value of data-driven robot control is somewhat limited though, as many robots are essentially a combination of rigid-body motion, vibrations, and actuation dynamics (all of which can be modeled).  While it is true the sensing can be challenging for small/low-cost systems, the use of state estimation is generally well-understood and standard practice.  (One possible counterexample is the use of cameras in the feedback loop, for robots performing complex manipulation tasks.)  Future work could instead focus on a specific problem which is known to be difficult from a control point of view, for which real-world datasets are available, and for which there are not obvious model-based solutions in practice, e.g. networked or distributed systems.  Observing patterns in singular values and evaluating mode decomposition could be a possible topic to explore for such a system.
}
\end{itemize}

\section{Source Code}
All MATLAB and LaTeX code used for this thesis can be found on GitHub at the following link: \url{https://github.com/josiahdelange/thesis}.
