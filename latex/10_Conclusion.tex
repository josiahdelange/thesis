\chapter{Conclusions and Future Work}
\label{chap:conclusion}
\section{Summary}
In this thesis, a preliminary look at the robustness of offline data-driven LMIs was presented as a surrogate for machine learning problems whose solutions can be found via convex optimization.  These methods consisted of searches with various constraints (Lyapunov stability, $\mathcal{H}_{2}$ optimality, $\mathcal{H}_{\infty}$ optimality) that calculate static state feedback control parameters, with or without intermediate system identification.

\begin{itemize}
\item{Baseline control designs stabilize between 67\% and 100\% of the parametric plant model perturbations.  The specific percentage, computed as a fraction of 100, depends inversely on the relative amount of uncertainty (parameterized using the scale factor) as is shown in Figure \ref{fig:overall_trends_uncertainty_opt_bar}.  In the case of measurement noise, shown in Figure \ref{fig:overall_trends_noise_opt_bar}, baseline control stability was mostly unaffected and stabilized at least 93\% of the noisy simulations, outside of one poorly performing case (with 60\% scale factor), in which the baseline $\mathcal{H}_{\infty}$ control only stabilized 17\% of the noisy simulations of the cart pole; this can be seen in the top row, middle column plot of Figure \ref{fig:overall_trends_noise_opt_bar}.  The specific percentage of stable feedback systems, along with most or all stability/performance margins, could be further improved with additional tuning of $\mathcal{H}_{2}$/$\mathcal{H}_{\infty}$ parameters (e.g., $\vb*{Q}_{x}$, $\vb*{R}_{u}$ matrices).}
%
\item{Indirectly computed data-driven designs stabilized between 70\% and 100\% of the parametric plant model perturbations.  As above, the specific percentage depends inversely on the relative amount of uncertainty and can be seen to roughly match the percentage stabilized by the baseline in Figure \ref{fig:overall_trends_uncertainty_opt_bar}.  However, in the case of measurement perturbations as shown in Figure \ref{fig:overall_trends_noise_opt_bar}, the indirect method stabilized between 37\% and 94\% of the noisy simulations, showing a clear inverse relationship with the scale factor of noise power.  Given 37\% $\ll$ 94\%, the accompanying stability/performance metrics are skewed and must be interpreted in that light.  Note that, in this broad range, the indirect method stabilized 90\% to 94\% of the noisy cart pole simulations.  Hence, while the indirect method is highly sensitive to measurement noise, its sensitivity also depends on the specific plant.  As above, the specific percentage of stable feedback systems could be improved through additional tuning of relevant optimization parameters, and likely, of the training policy in order to improve the relative signal-to-noise ratio (SNR) of the information contained in the training data.}
%
\item{Directly computed data-driven designs stabilized between 49\% and 100\% of the parametric plant model perturbations.  As above, the specific percentage depends inversely on the relative amount of uncertainty and can be seen in Figure \ref{fig:overall_trends_uncertainty_opt_bar} to stabilize fewer model perturbations than the baseline.  Specifically, for the double integrator and robot arm, the direct method stabilized a lower fraction of plant model perturbations than the baseline control; for the cart pole, it stabilized approximately the same.  As before, because 49\% $\ll$ 100\%, the results are skewed and must be interpreted in that light.  In the case of measurement perturbations, shown in Figure \ref{fig:overall_trends_noise_opt_bar}, the direct method performed extremely poorly and could not stabilize plant model perturbations with a scale factor of just 10\%.  Due to the nature of the direct LMIs, this implies the data-driven optimization problems specified were unable to find a solution.  Hence, the direct method is extremely sensitive to noise, more so than the indirect method.
}
%
\item{After observing the poor performance of the direct LMI-based approach, the suboptimal variant described in Section \ref{sect:dataDrivenH2Suboptimal} was tested for comparison.  It was anticipated this may increase the number of stabilizing controllers, if the LMI solver used for the direct method was, e.g., near a stabilizing solution with a higher-than-optimal cost.  Re-running the tests with this modification, the direct approach was able to stabilize a slightly higher percentage of the parametric plant model perturbations, but this had little effect on the ability to synthesize controllers when subjected instead to measurement perturbations.  The corresponding plots are seen in Figures \ref{fig:overall_trends_uncertainty_subopt_bar} and \ref{fig:overall_trends_noise_subopt_bar}.  Hence, in the context of this thesis, it appears that the data-driven $\mathcal{H}_{2}$ LMI becomes non-smooth / non-convex without perfect state measurements.  Corresponding analyses of data-driven $\mathcal{H}_{\infty}$ is left for future work.}
\end{itemize}

\section{Observations}
For baseline methods, it was demonstrated that, when solving for $\mathcal{H}_{\infty}$-optimal control using the DGARE and bisection, the minimax/optimal value of disturbance attenuation constant $\gamma^{*}$ produced fragile feedback systems whose responses to the modeled disturbances are evenly spread throughout all frequencies.  However, by relaxing the optimality of the synthesis procedure with respect to the desired $\gamma \geq \gamma^{*}$, this effect becomes less prominent.  For all three case studies, this ``waterbed effect'' was clear when examining the frequency-dependent loop shape of the generalized plant's singular values.  This is important to keep in mind when designing static $\mathcal{H}_{\infty}$ controllers using state-space methods.

For data-driven methods, many factors are held constant (e.g. the training policy, the amount of data used for learning, the performance cost parameters) and simplifying assumptions were made (e.g., no rate limits or saturation, simplified inertial properties).  Still, it was demonstrated that the model-free approaches can tolerate low to moderate amounts of single parameter uncertainty.  Additive white Gaussian measurement noise can be handled to a certain degree by using the indirect SVD-based approach, which inherently suppresses uncorrelated noise (data not attributable to the transient of a dynamic mode).  Even when no exact solution exists to the data-driven synthesis problem, the SVD-based least squares algorithm effectively finds a practically-usable suboptimal solution.

The poor performance of data-driven $\mathcal{H}_{2}$ LMIs with noisy data is expected based on the assumption of having perfect state feedback.  When this is not the case, the resulting problem can become non-convex to the point of infeasibility, resulting in the LMI solver returning a ``no solution'' condition, despite the high likelihood of nearby suboptimal solutions that stabilize the system.  It should be the case that the direct approach searches for the lowest-cost solution that is constrained to incorporate closed-loop stability.  However, for the problems examined in this thesis, it seems necessary to encode some expected performance loss or expected uncertainty into the LMI, and/or for example, in the case of $\mathcal{H}_{\infty}$ control, seek to understand the optimization landscape of the control problem with respect to both stability and various metrics of robustness.  Whether this combined search problem is computationally feasible, convex, or amenable to data-driven/reinforcement learning is left for future work.

\section{Additional Remarks}
Apart from the specific numerical results, several additional lessons were learned while developing this thesis.

The field of robust control, with its associated tools and techniques, is both very powerful and very mathematically involved.  However, it is heavily dependent on dynamic modeling of the uncertain system to be controlled.  Fortunately, modern software toolboxes/libraries can automate the solution to control design when transcribed as a mathematical optimization, but only when they are provided an accurate model of the disturbances and/or uncertainty faced by the real system.  Indeed, much of the practical work involved with robust control involves derivation of disturbance models and heuristic tuning of either control gains or cost weights used to compute control gains; in both cases, one leans heavily on domain-specific insight into the system being controlled.

By contrast, literature in some more computationally-focused aspects of control theory, including data-driven control and learning/optimization, often focuses more on theoretical aspects of algorithms (e.g. convergence properties, convexity, sample efficiency).  To this end, the case study dynamical systems used to test and verify numerical techniques are purposely simplified or generalized to omit the practical aspects of incorporating real-world effects into the system being learned/optimized.  Incorporating, for example, low-frequency parameter uncertainty or measurement noise (or uncertainty induced by state estimation) is not immediately obvious, or possibly feasible, using standard convex optimization paradigms.  Many similar problems are the subject of current research in robust learning.

When exploring the intersection between these two fields, as was initially the goal of this thesis, it is important to pick and focus on a somewhat smaller problem to benchmark.  Maintaining and tuning multiple simulators with a large number of parameters (e.g., cost weights, training policies and durations, plant inertial parameters, measurement noise models, initial conditions for simulation, disturbance models) and attempting to analyze properties empirically (e.g. using repeated-trial or Monte-Carlo type tests) can quickly lead to an overabundance of data, making it difficult to concisely summarize the results.  Because the efficacy and robustness of data-driven control depends on a wide range of factors, evaluating different aspects is best done incrementally using smaller, more targeted analyses on a particular system.  For example, focusing on the cart pole for future analysis may allow comparison to known results in robustness/sensitivity \cite{leong2016understanding,bernat2020driver}.

\section{Future Work}
Several areas of this work were purposely oversimplified in the interest of time, and would be interesting to explore further.
\begin{itemize}
\item{\textbf{Loop Shaping:} The time-domain, game-theoretic solution to $\mathcal{H}_{\infty}$ control used in this work operates on a general state-space representation of the plant.  Cost and disturbance weights are constant matrices that are independent of frequency.  In order to utilize loop-shaping techniques, the plant's state-space model would need to be augmented with loop-shaping filters.  Interestingly, the data-driven equivalent of this problem was considered in \cite{berberich2022combining}, treating this augmented plant as partially known; filter dynamics are known, but the system dynamics are learned from data.  This seems like the right approach for further investigation of data-driven $\mathcal{H}_{\infty}$ and possibly the effect of state estimation on loop shape.  For example, robotic control involving frequency-dependent actuator dynamics may benefit from loop-shaping designs.
}
%
\item{\textbf{Disturbance Modeling:}
Disturbance modeling is an important aspect of robust control.  However, applying robust control theory to model-free learning brings up other interesting questions.  How much of the disturbance/uncertainty can be understood and/or modeled?  Can disturbances be modeled in a way that is flexible enough to incorporate new data that contradicts the \emph{a priori} model?  In the specific context of this work, one direction that should be expanded on is the effect of cost weighting matrices other than those associated with LQ performance.  It would be interesting to study how different performance and disturbance weights perform in model-based contexts vs. model-free contexts.  Perhaps higher-dimensional statistical techniques could be used to estimate disturbance bounds from gathered data.
}
%
\item{\textbf{Optimization Algorithms:}
This thesis aimed to evaluate specific offline techniques from \cite{de2019formulas} in the presence of uncertainty and noise, but many applications of reinforcement learning are based on the assumption of online adaptation of the control policy.  In particular, RL often involves some form of policy optimization, which can include, e.g., policy gradient methods, actor-critic methods, trust-region methods, etc.  For the LQR problem, these approaches are well-understood \cite{malik2019derivative}.  Extensions to dynamic controllers \cite{zheng2022escaping} and filters \cite{umenberger2022globally} for the LQG problem, as well as the mixed $\mathcal{H}_{2}$/$\mathcal{H}_{\infty}$ problem \cite{zhang2021derivative, zhang2020policy} have been investigated, but are noted as being non-convex.  Thus, future work in data-driven optimization should investigate algorithms for non-convex problems, and those that explicitly consider uncertainty in the problem data.  Indeed, the results of this thesis illustrate clearly that optimizing under the assumption of perfect state feedback is likely to be insufficient in scenarios with high uncertainty/noise.  Optimization algorithms that deal with uncertainty have been developed using the theoretical framework known as ``robust optimization'' \cite{soyster1973convex, ei1997robust, el1998robust, ben1999robust, ben2001lectures, ben2002robust, bertsimas2003robust, bertsimas2004price, joelianto5417249}.
}
%
\item{\textbf{Non-Robotic Systems:}
For the purposes of this work, robotic systems were selected for theoretical simplicity.  The practical value of data-driven robot control is somewhat limited though, as many robots are essentially a combination of rigid-body motion, vibrations, and actuation dynamics (all of which can be modeled).  While it is true the sensing can be challenging for small/low-cost systems, the use of state estimation is generally well-understood and standard practice.  (One possible counterexample is the use of cameras in the feedback loop, for robots performing complex manipulation tasks.)  Future work could instead focus on a specific problem that is known to be difficult from a control point of view, for which real-world datasets are available, and for which there are not obvious model-based solutions in practice, e.g. networked or distributed systems.  Observing patterns in singular values and evaluating mode decomposition could be a possible topic to explore for such a system.
}
\end{itemize}

\section{Source Code}
All MATLAB and LaTeX code used for this thesis can be found on GitHub at the following link: \url{https://github.com/josiahdelange/thesis}.
