%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Josiah at 2023-01-07 18:10:50 -0500 


%% Saved with string encoding Unicode (UTF-8) 

@book{slotineli,
	author = {Slotine, Jean-Jacques E and Li, Weiping and others},
	number = {1},
	publisher = {Prentice hall Englewood Cliffs, NJ},
	title = {{Applied Nonlinear Control}},
	volume = {199},
	year = {1991}}

@article{kalman1960contributions,
	author = {Kalman, Rudolf Emil and others},
	journal = {Bol. soc. mat. mexicana},
	number = {2},
	pages = {102--119},
	title = {{Contributions to the Theory of Optimal Control}},
	volume = {5},
	year = {1960}}

@article{bryson1996optimal,
  title={{Optimal Control - 1950 to 1985}},
  author={Bryson, Arthur E},
  journal={IEEE Control Systems Magazine},
  volume={16},
  number={3},
  pages={26--33},
  year={1996},
  publisher={IEEE}
}

@book{bertsekas2012dynamic,
	author = {Bertsekas, Dimitri},
	publisher = {Athena scientific},
	title = {{Dynamic Programming and Optimal Control: Volume I}},
	volume = {1},
	year = {2012}}

@book{stengel,
	author = {Stengel, Robert F},
	publisher = {Courier Corporation},
	title = {{Optimal Control and Estimation}},
	year = {1994}}

@book{kirk,
	author = {Kirk, Donald E},
	publisher = {Courier Corporation},
	title = {{Optimal Control Theory: An Introduction}},
	year = {2004}}

@article{sutton1992reinforcement,
	author = {Sutton, Richard S and Barto, Andrew G and Williams, Ronald J},
	journal = {IEEE control systems magazine},
	number = {2},
	pages = {19--22},
	publisher = {IEEE},
	title = {{Reinforcement Learning is Direct Adaptive Optimal Control}},
	volume = {12},
	year = {1992}}

@article{bradtke1992reinforcement,
	author = {Bradtke, Steven},
	journal = {Advances in neural information processing systems},
	title = {{Reinforcement Learning Applied to Linear Quadratic Regulation}},
	volume = {5},
	year = {1992}}

@inproceedings{bradtke1994adaptive,
	author = {Bradtke, Steven J and Ydstie, B Erik and Barto, Andrew G},
	booktitle = {Proceedings of 1994 American Control Conference-ACC'94},
	organization = {IEEE},
	pages = {3475--3479},
	title = {{Adaptive Linear Quadratic Control Using Policy Iteration}},
	volume = {3},
	year = {1994}}

@inproceedings{lamperski2020computing,
	author = {Lamperski, Andrew},
	booktitle = {2020 59th IEEE Conference on Decision and Control (CDC)},
	organization = {IEEE},
	pages = {1902--1907},
	title = {{Computing Stabilizing Linear Controllers via Policy Iteration}},
	year = {2020}}

@article{yaghmaie2022linear,
	author = {Yaghmaie, Farnaz Adib and Gustafsson, Fredrik and Ljung, Lennart},
	journal = {IEEE Transactions on Automatic Control},
	publisher = {IEEE},
	title = {{Linear Quadratic Control Using Model-Free Reinforcement Learning}},
	year = {2022}}

@inproceedings{yaghmaie2019using,
	author = {Yaghmaie, Farnaz Adib and Gustafsson, Fredrik},
	booktitle = {2019 IEEE 58th Conference on Decision and Control (CDC)},
	organization = {IEEE},
	pages = {6510--6517},
	title = {{Using Reinforcement Learning for Model-Free Linear Quadratic Control with Process and Measurement Noises}},
	year = {2019}}

@inproceedings{lewis2009adaptive,
	author = {Lewis, Frank L and Vrabie, Draguna},
	booktitle = {2009 7th Asian Control Conference},
	organization = {IEEE},
	pages = {1402--1409},
	title = {{Adaptive Dynamic Programming for Feedback Control}},
	year = {2009}}

@article{lewis2009reinforcement,
	author = {Lewis, Frank L and Vrabie, Draguna},
	journal = {IEEE circuits and systems magazine},
	number = {3},
	pages = {32--50},
	publisher = {IEEE},
	title = {{Reinforcement Learning and Adaptive Dynamic Programming for Feedback Control}},
	volume = {9},
	year = {2009}}

@article{farjadnasab2022model,
	author = {Farjadnasab, Milad and Babazadeh, Maryam},
	journal = {Automatica},
	pages = {110060},
	publisher = {Elsevier},
	title = {{Model-Free LQR Design by Q-Function Learning}},
	volume = {137},
	year = {2022}}

@article{wong2010reinforcement,
	author = {Wong, Wee Chin and Lee, Jay H},
	journal = {Optimal Control Applications and Methods},
	number = {4},
	pages = {365--374},
	publisher = {Wiley Online Library},
	title = {{A Reinforcement Learning-Based Scheme for Direct Adaptive Optimal Control of Linear Stochastic Systems}},
	volume = {31},
	year = {2010}}

@inproceedings{lale2021adaptive,
	author = {Lale, Sahin and Azizzadenesheli, Kamyar and Hassibi, Babak and Anandkumar, Anima},
	booktitle = {2021 American Control Conference (ACC)},
	organization = {IEEE},
	pages = {2517--2522},
	title = {{Adaptive Control and Regret Minimization in Linear Quadratic Gaussian (LQG) Setting}},
	year = {2021}}

@inproceedings{chen2019adaptive,
	author = {Chen, Anthony Siming and Herrmann, Guido},
	booktitle = {2019 IEEE 58th Conference on Decision and Control (CDC)},
	organization = {IEEE},
	pages = {1007--1012},
	title = {{Adaptive Optimal Control via Continuous-Time Q-Learning for Unknown Nonlinear Affine Systems}},
	year = {2019}}

@inproceedings{cui2021combined,
	author = {Cui, Leilei and Ozbay, Kaan and Jiang, Zhong-Ping},
	booktitle = {2021 American Control Conference (ACC)},
	organization = {IEEE},
	pages = {1929--1934},
	title = {{Combined Longitudinal and Lateral Control of Autonomous Vehicles based on Reinforcement Learning}},
	year = {2021}}

@inproceedings{matni2019self,
	author = {Matni, Nikolai and Proutiere, Alexandre and Rantzer, Anders and Tu, Stephen},
	booktitle = {2019 IEEE 58th Conference on Decision and Control (CDC)},
	organization = {IEEE},
	pages = {3724--3740},
	title = {{From Self-Tuning Regulators to Reinforcement Learning and Back Again}},
	year = {2019}}

@article{yang2021model,
	author = {Yang, Yongliang and Kiumarsi, Bahare and Modares, Hamidreza and Xu, Chengzhong},
	date-modified = {2023-01-07 18:10:23 -0500},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	publisher = {IEEE},
	title = {{Model-Free $\lambda$-Policy Iteration for Discrete-Time Linear Quadratic Regulation}},
	year = {2021}}

@article{rizvi2018output,
	author = {Rizvi, Syed Ali Asad and Lin, Zongli},
	journal = {IEEE transactions on neural networks and learning systems},
	number = {5},
	pages = {1523--1536},
	publisher = {IEEE},
	title = {{Output Feedback Q-Learning Control for the Discrete-Time Linear Quadratic Regulator Problem}},
	volume = {30},
	year = {2018}}

@inproceedings{cohen2018online,
	author = {Cohen, Alon and Hasidim, Avinatan and Koren, Tomer and Lazic, Nevena and Mansour, Yishay and Talwar, Kunal},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {1029--1038},
	title = {{Online Linear Quadratic Control}},
	year = {2018}}

@inproceedings{malik2019derivative,
	author = {Malik, Dhruv and Pananjady, Ashwin and Bhatia, Kush and Khamaru, Koulik and Bartlett, Peter and Wainwright, Martin},
	booktitle = {The 22nd international conference on artificial intelligence and statistics},
	organization = {PMLR},
	pages = {2916--2925},
	title = {{Derivative-Free Methods for Policy Optimization: Guarantees for Linear Quadratic Systems}},
	year = {2019}}

@article{dean2020sample,
	author = {Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
	journal = {Foundations of Computational Mathematics},
	number = {4},
	pages = {633--679},
	publisher = {Springer},
	title = {{On the Sample Complexity of the Linear Quadratic Regulator}},
	volume = {20},
	year = {2020}}

@article{moos2022robust,
	author = {Moos, Janosch and Hansel, Kay and Abdulsamad, Hany and Stark, Svenja and Clever, Debora and Peters, Jan},
	journal = {Machine Learning and Knowledge Extraction},
	number = {1},
	pages = {276--315},
	publisher = {MDPI},
	title = {{Robust Reinforcement Learning: A Review of Foundations and Recent Advances}},
	volume = {4},
	year = {2022}}

@inproceedings{venkataraman2019recovering,
	author = {Venkataraman, Harish K and Seiler, Peter J},
	booktitle = {2019 American Control Conference (ACC)},
	organization = {IEEE},
	pages = {4210--4216},
	title = {{Recovering Robustness in Model-Free Reinforcement Learning}},
	year = {2019}}

@inproceedings{roberts2011feedback,
	author = {Roberts, John W and Manchester, Ian R and Tedrake, Russ},
	booktitle = {2011 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
	organization = {IEEE},
	pages = {310--317},
	title = {{Feedback Controller Parameterizations for Reinforcement Learning}},
	year = {2011}}

@article{pang2022robust,
	author = {Pang, Bo and Jiang, Zhong-Ping},
	journal = {Trends in Nonlinear and Adaptive Control},
	pages = {249--277},
	publisher = {Springer},
	title = {{Robust Reinforcement Learning for Stochastic Linear Quadratic Control with Multiplicative Noise}},
	year = {2022}}

@article{umenberger2019robust,
	author = {Umenberger, Jack and Ferizbegovic, Mina and Sch{\"o}n, Thomas B and Hjalmarsson, H{\aa}kan},
	journal = {Advances in Neural Information Processing Systems},
	title = {{Robust Exploration in Linear Quadratic Reinforcement Learning}},
	volume = {32},
	year = {2019}}

@article{dean2018regret,
	author = {Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
	journal = {Advances in Neural Information Processing Systems},
	title = {{Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator}},
	volume = {31},
	year = {2018}}

@inproceedings{ho2019robust,
	author = {Ho, Dimitar and Doyle, John C},
	booktitle = {2019 IEEE 58th Conference on Decision and Control (CDC)},
	date-modified = {2023-01-07 18:10:47 -0500},
	organization = {IEEE},
	pages = {4577--4582},
	title = {{Robust Model-Free Learning and Control Without Prior Knowledge}},
	year = {2019}}

@inproceedings{bernat2020driver,
	author = {Bernat, Natalie and Chen, Jiexin and Matni, Nikolai and Doyle, John},
	booktitle = {2020 American Control Conference (ACC)},
	organization = {IEEE},
	pages = {3932--3939},
	title = {{The Driver and The Engineer: Reinforcement Learning and Robust Control}},
	year = {2020}}

@article{al2007model,
	author = {Al-Tamimi, Asma and Lewis, Frank L and Abu-Khalaf, Murad},
	journal = {Automatica},
	number = {3},
	pages = {473--481},
	publisher = {Elsevier},
	title = {{Model-Free Q-Learning Designs for Linear Discrete-Time Zero-Sum Games with Application to $\mathcal{H}_{\infty}$ Control}},
	volume = {43},
	year = {2007}}

@inproceedings{al2007model2,
	author = {Al-Tamimi, Asma and Lewis, Frank L and Wang, Youyi},
	booktitle = {2007 IEEE 22nd International Symposium on Intelligent Control},
	organization = {IEEE},
	pages = {118--125},
	title = {{Model-Free $\mathcal{H}_{\infty}$ Load-Frequency Controller Design for Power Systems}},
	year = {2007}}

@article{zhang2021derivative,
	author = {Zhang, Kaiqing and Zhang, Xiangyuan and Hu, Bin and Basar, Tamer},
	journal = {Advances in Neural Information Processing Systems},
	pages = {2949--2964},
	title = {{Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust Control Design: Implicit Regularization and Sample Complexity}},
	volume = {34},
	year = {2021}}

@inproceedings{zhang2020policy,
	author = {Zhang, Kaiqing and Hu, Bin and Basar, Tamer},
	booktitle = {Learning for Dynamics and Control},
	organization = {PMLR},
	pages = {179--190},
	title = {{Policy Optimization for $\mathcal{H}_{2}$ Linear Control with $\mathcal{H}_{\infty}$ Robustness Guarantee: Implicit Regularization and Global Convergence}},
	year = {2020}}
